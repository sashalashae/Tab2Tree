{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema Robustness Evaluation Project (with Real Adult Dataset)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# 1. Load Real Adult Dataset from UCI\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(url, names=columns, sep=',\\s*', engine='python')\n",
    "\n",
    "# Clean missing data\n",
    "df = df.replace('?', np.nan).dropna()\n",
    "\n",
    "# Drop 'fnlwgt' and 'education-num' for simplicity\n",
    "df = df.drop(columns=['fnlwgt', 'education-num'])\n",
    "\n",
    "# 2. Schema Shift: Rename Columns\n",
    "rename_map = {col: f\"col_{col}\" for col in df.columns if col != 'income'}\n",
    "df_renamed = df.rename(columns=rename_map)\n",
    "\n",
    "# 3. Category Merge Example\n",
    "df['marital-status'] = df['marital-status'].replace({'Divorced': 'Formerly-Married', 'Widowed': 'Formerly-Married'})\n",
    "\n",
    "# 4. Feature Composition Example\n",
    "df['age_bracket'] = pd.cut(df['age'], bins=[0, 30, 50, 100], labels=['Young','Middle','Senior'])\n",
    "\n",
    "# 5. Convert Dataset to JSON and XML (sampled)\n",
    "json_data = []\n",
    "xml_data = []\n",
    "for _, row in df.sample(n=100, random_state=42).iterrows():\n",
    "    rec = row.to_dict()\n",
    "    json_rec = {\n",
    "        \"demographics\": {k: rec[k] for k in ['age','sex','race','marital-status']},\n",
    "        \"education\": rec['education'],\n",
    "        \"work\": {\"workclass\": rec['workclass'], \"hours-per-week\": rec['hours-per-week']},\n",
    "        \"income\": rec['income']\n",
    "    }\n",
    "    json_data.append(json_rec)\n",
    "\n",
    "    root = ET.Element(\"Person\")\n",
    "    dem = ET.SubElement(root, \"Demographics\")\n",
    "    for k in ['age','sex','race','marital-status']:\n",
    "        ET.SubElement(dem, k.replace('-','_')).text = str(rec[k])\n",
    "    wk = ET.SubElement(root, \"Work\")\n",
    "    ET.SubElement(wk, \"workclass\").text = rec['workclass']\n",
    "    ET.SubElement(wk, \"hours_per_week\").text = str(rec['hours-per-week'])\n",
    "    ET.SubElement(root, \"income\").text = rec['income']\n",
    "    xml_data.append(ET.tostring(root).decode())\n",
    "\n",
    "# 6. Structural Similarity Index (SSI)\n",
    "def structural_similarity(json1, json2):\n",
    "    return SequenceMatcher(None, json.dumps(json1, sort_keys=True), json.dumps(json2, sort_keys=True)).ratio()\n",
    "\n",
    "# 7. Key Alignment Accuracy (KAA)\n",
    "def key_alignment(json1, json2):\n",
    "    keys1 = set(json.dumps(json1).replace('{','').replace('}','').split(':'))\n",
    "    keys2 = set(json.dumps(json2).replace('{','').replace('}','').split(':'))\n",
    "    if not keys1: return 0\n",
    "    return len(keys1 & keys2) / len(keys1)\n",
    "\n",
    "# 8. Prepare Train/Test Data\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['income'])\n",
    "X = pd.get_dummies(df.drop(columns='income'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 9. Train Models\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=0)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(16,), max_iter=100, random_state=0)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# 10. Evaluate on Original Test\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "y_pred_mlp = mlp_clf.predict(X_test)\n",
    "print(\"Original XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"Original MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
    "\n",
    "# 11. Simulate Renamed Schema on Test\n",
    "X_test_renamed = X_test.rename(columns={col: f\"col_{col}\" for col in X_test.columns})\n",
    "X_test_renamed_aligned = X_test_renamed.reindex(columns=X_train.columns, fill_value=0)\n",
    "y_pred_xgb_bad = xgb_clf.predict(X_test_renamed_aligned)\n",
    "y_pred_mlp_bad = mlp_clf.predict(X_test_renamed_aligned)\n",
    "print(\"Renamed (no fix) XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb_bad))\n",
    "print(\"Renamed (no fix) MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp_bad))\n",
    "\n",
    "# 12. Dictionary Mapping Fix\n",
    "inv_map = {f\"col_{col}\": col for col in X_train.columns}\n",
    "X_test_mapped = X_test_renamed.rename(columns=inv_map)\n",
    "X_test_mapped_aligned = X_test_mapped.reindex(columns=X_train.columns, fill_value=0)\n",
    "y_pred_xgb_corr = xgb_clf.predict(X_test_mapped_aligned)\n",
    "y_pred_mlp_corr = mlp_clf.predict(X_test_mapped_aligned)\n",
    "print(\"Renamed + Mapping XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb_corr))\n",
    "print(\"Renamed + Mapping MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp_corr))\n",
    "\n",
    "# 13. Embedding-Based Fix (Using Sentence-BERT)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def match_columns_by_embedding(renamed_cols, train_cols):\n",
    "    emb_renamed = model.encode(renamed_cols)\n",
    "    emb_train = model.encode(train_cols)\n",
    "    sim_matrix = cosine_similarity(emb_renamed, emb_train)\n",
    "    best_match = sim_matrix.argmax(axis=1)\n",
    "    return {renamed_cols[i]: train_cols[best_match[i]] for i in range(len(renamed_cols))}\n",
    "\n",
    "embedding_map = match_columns_by_embedding(X_test_renamed.columns.tolist(), X_train.columns.tolist())\n",
    "X_test_emb_mapped = X_test_renamed.rename(columns=embedding_map)\n",
    "X_test_emb_aligned = X_test_emb_mapped.reindex(columns=X_train.columns, fill_value=0)\n",
    "y_pred_xgb_emb = xgb_clf.predict(X_test_emb_aligned)\n",
    "y_pred_mlp_emb = mlp_clf.predict(X_test_emb_aligned)\n",
    "print(\"Renamed + Embedding XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb_emb))\n",
    "print(\"Renamed + Embedding MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp_emb))\n",
    "\n",
    "# 14. Evaluate Structural Metrics\n",
    "ssi_scores = []\n",
    "kaa_scores = []\n",
    "for i in range(min(50, len(json_data))):\n",
    "    json_shifted = json.loads(json.dumps(json_data[i]).replace('workclass','employment').replace('marital-status','maritalstatus'))\n",
    "    ssi_scores.append(structural_similarity(json_data[i], json_shifted))\n",
    "    kaa_scores.append(key_alignment(json_data[i], json_shifted))\n",
    "\n",
    "print(\"Avg Structural Similarity Index (SSI):\", np.mean(ssi_scores))\n",
    "print(\"Avg Key Alignment Accuracy (KAA):\", np.mean(kaa_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c407ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
