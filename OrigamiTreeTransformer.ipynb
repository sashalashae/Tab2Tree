{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YObBYk0oHv6c",
        "outputId": "51a1493e-42a5-4e32-a95a-9416bc73a0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGAMI JSON Accuracy: 0.55 F1: 0.0\n",
            "TreeTransformer JSON Accuracy: 1.0 F1: 1.0\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Hierarchical Schema Robustness: ORIGAMI + TreeTransformer\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# -------------------------\n",
        "# 1. Load Adult Dataset\n",
        "# -------------------------\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = [\n",
        "    \"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\n",
        "    \"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\n",
        "    \"hours-per-week\",\"native-country\",\"income\"\n",
        "]\n",
        "\n",
        "df = pd.read_csv(url, names=columns, sep=r\",\\s*\", engine=\"python\")\n",
        "df = df.replace(\"?\", np.nan).dropna()\n",
        "df = df.drop(columns=[\"fnlwgt\",\"education-num\"])\n",
        "\n",
        "# -------------------------\n",
        "# 2. JSON Conversion\n",
        "# -------------------------\n",
        "\n",
        "json_data = []\n",
        "labels = []\n",
        "\n",
        "for _, r in df.sample(n=100, random_state=42).iterrows():\n",
        "    rec = r.to_dict()\n",
        "    json_data.append({\n",
        "        \"demographics\":{\n",
        "            \"age\":rec[\"age\"],\n",
        "            \"sex\":rec[\"sex\"],\n",
        "            \"race\":rec[\"race\"],\n",
        "            \"marital-status\":rec[\"marital-status\"]\n",
        "        },\n",
        "        \"education\":rec[\"education\"],\n",
        "        \"work\":{\n",
        "            \"workclass\":rec[\"workclass\"],\n",
        "            \"hours-per-week\":rec[\"hours-per-week\"]\n",
        "        },\n",
        "        \"income\":rec[\"income\"]\n",
        "    })\n",
        "    labels.append(1 if rec[\"income\"] == \">50K\" else 0)\n",
        "\n",
        "# -------------------------\n",
        "# 3. JSON â†’ Tree Nodes\n",
        "# -------------------------\n",
        "\n",
        "def json_to_nodes(obj, prefix=\"\", depth=0):\n",
        "    nodes = []\n",
        "    if isinstance(obj, dict):\n",
        "        for k,v in obj.items():\n",
        "            nodes.extend(json_to_nodes(v, f\"{prefix}.{k}\" if prefix else k, depth+1))\n",
        "    else:\n",
        "        nodes.append((prefix.replace(\"-\",\"_\"), str(obj), depth))\n",
        "    return nodes\n",
        "\n",
        "nodes = [json_to_nodes(j) for j in json_data]\n",
        "\n",
        "# -------------------------\n",
        "# 4. Linearization (ORIGAMI)\n",
        "# -------------------------\n",
        "\n",
        "def linearize(nodes):\n",
        "    return \" \".join([f\"{k}={v}\" for k,v,_ in nodes])\n",
        "\n",
        "texts = [linearize(n) for n in nodes]\n",
        "\n",
        "# -------------------------\n",
        "# 5. Vocabulary\n",
        "# -------------------------\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self):\n",
        "        self.stoi = {\"<pad>\":0}\n",
        "        self.itos = [\"<pad>\"]\n",
        "\n",
        "    def add(self, text):\n",
        "        for t in text.split():\n",
        "            if t not in self.stoi:\n",
        "                self.stoi[t] = len(self.itos)\n",
        "                self.itos.append(t)\n",
        "\n",
        "    def encode(self, text, L):\n",
        "        ids = [self.stoi.get(t,0) for t in text.split()][:L]\n",
        "        return ids + [0]*(L-len(ids))\n",
        "\n",
        "vocab = Vocab()\n",
        "for t in texts:\n",
        "    vocab.add(t)\n",
        "\n",
        "# -------------------------\n",
        "# 6. Train/Test Split\n",
        "# -------------------------\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(\n",
        "    list(range(len(nodes))), labels, test_size=0.2, random_state=0\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 7. ORIGAMI Dataset\n",
        "# -------------------------\n",
        "\n",
        "class ORIGAMIDS(Dataset):\n",
        "    def __init__(self, idxs, nodes, labels, vocab, L=256):\n",
        "        self.X = [vocab.encode(linearize(nodes[i]), L) for i in idxs]\n",
        "        self.y = [labels[i] for i in idxs]\n",
        "\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self,i):\n",
        "        return torch.tensor(self.X[i]), torch.tensor(self.y[i])\n",
        "\n",
        "# -------------------------\n",
        "# 8. Tree Dataset\n",
        "# -------------------------\n",
        "\n",
        "class TreeDS(Dataset):\n",
        "    def __init__(self, idxs, nodes, labels, vocab, max_nodes=64):\n",
        "        self.nodes = nodes\n",
        "        self.labels = labels\n",
        "        self.idxs = idxs\n",
        "        self.vocab = vocab\n",
        "        self.max_nodes = max_nodes\n",
        "\n",
        "    def __len__(self): return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        idx = self.idxs[i]\n",
        "        node_ids, depths = [], []\n",
        "        for k,v,d in self.nodes[idx][:self.max_nodes]:\n",
        "            tok = f\"{k}={v}\"\n",
        "            node_ids.append(self.vocab.encode(tok,1))\n",
        "            depths.append(min(d,31))\n",
        "        while len(node_ids) < self.max_nodes:\n",
        "            node_ids.append([0])\n",
        "            depths.append(0)\n",
        "        return (\n",
        "            torch.tensor(node_ids),\n",
        "            torch.tensor(depths),\n",
        "            torch.tensor(self.labels[idx])\n",
        "        )\n",
        "\n",
        "# -------------------------\n",
        "# 9. ORIGAMI Model\n",
        "# -------------------------\n",
        "\n",
        "class ORIGAMI(nn.Module):\n",
        "    def __init__(self, vocab_size, d=128):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, d)\n",
        "        enc = nn.TransformerEncoderLayer(d, 4, 256, batch_first=True)\n",
        "        self.tr = nn.TransformerEncoder(enc, 2)\n",
        "        self.fc = nn.Linear(d,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        h = self.tr(self.emb(x))\n",
        "        return self.fc(h.mean(1))\n",
        "\n",
        "# -------------------------\n",
        "# 10. TreeTransformer Model\n",
        "# -------------------------\n",
        "\n",
        "class TreeTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d=128):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, d)\n",
        "        self.depth = nn.Embedding(32, d)\n",
        "        enc = nn.TransformerEncoderLayer(d, 4, 256, batch_first=True)\n",
        "        self.tr = nn.TransformerEncoder(enc, 2)\n",
        "        self.fc = nn.Linear(d,2)\n",
        "\n",
        "    def forward(self,x,depth):\n",
        "        h = self.emb(x).mean(2) + self.depth(depth)\n",
        "        return self.fc(self.tr(h).mean(1))\n",
        "\n",
        "# -------------------------\n",
        "# 11. Training Helpers\n",
        "# -------------------------\n",
        "\n",
        "def train_epoch(model, loader, opt, tree=False):\n",
        "    model.train()\n",
        "    for batch in loader:\n",
        "        opt.zero_grad()\n",
        "        if tree:\n",
        "            x,d,y = batch\n",
        "            out = model(x,d)\n",
        "        else:\n",
        "            x,y = batch\n",
        "            out = model(x)\n",
        "        loss = nn.CrossEntropyLoss()(out,y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "def evaluate(model, loader, tree=False):\n",
        "    model.eval()\n",
        "    y,p = [],[]\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            if tree:\n",
        "                x,d,t = batch\n",
        "                out = model(x,d)\n",
        "            else:\n",
        "                x,t = batch\n",
        "                out = model(x)\n",
        "            p.extend(out.argmax(1).numpy())\n",
        "            y.extend(t.numpy())\n",
        "    return accuracy_score(y,p), f1_score(y,p)\n",
        "\n",
        "# -------------------------\n",
        "# 12. Run ORIGAMI\n",
        "# -------------------------\n",
        "\n",
        "origami_tr = DataLoader(ORIGAMIDS(Xtr,nodes,labels,vocab), batch_size=16, shuffle=True)\n",
        "origami_te = DataLoader(ORIGAMIDS(Xte,nodes,labels,vocab), batch_size=16)\n",
        "\n",
        "origami = ORIGAMI(len(vocab.itos))\n",
        "opt_o = torch.optim.AdamW(origami.parameters(), 2e-4)\n",
        "\n",
        "for _ in range(6):\n",
        "    train_epoch(origami, origami_tr, opt_o)\n",
        "\n",
        "acc_o, f1_o = evaluate(origami, origami_te)\n",
        "print(\"ORIGAMI JSON Accuracy:\", acc_o, \"F1:\", f1_o)\n",
        "\n",
        "# -------------------------\n",
        "# 13. Run TreeTransformer\n",
        "# -------------------------\n",
        "\n",
        "tree_tr = DataLoader(TreeDS(Xtr,nodes,labels,vocab), batch_size=16, shuffle=True)\n",
        "tree_te = DataLoader(TreeDS(Xte,nodes,labels,vocab), batch_size=16)\n",
        "\n",
        "tree = TreeTransformer(len(vocab.itos))\n",
        "opt_t = torch.optim.AdamW(tree.parameters(), 2e-4)\n",
        "\n",
        "for _ in range(6):\n",
        "    train_epoch(tree, tree_tr, opt_t, tree=True)\n",
        "\n",
        "acc_t, f1_t = evaluate(tree, tree_te, tree=True)\n",
        "print(\"TreeTransformer JSON Accuracy:\", acc_t, \"F1:\", f1_t)\n"
      ]
    }
  ]
}